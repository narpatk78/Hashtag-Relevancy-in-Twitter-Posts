{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a0a37df5",
   "metadata": {},
   "source": [
    "<center>\n",
    "    \n",
    "# Hashtag Relevancy\n",
    "    \n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a4db1b7",
   "metadata": {},
   "source": [
    "#### importing required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f9468c36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from transformers import BertTokenizer, BertModel\n",
    "import torch\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9479299a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the preprocessed data from the Excel file\n",
    "data = pd.read_excel(\"preprocessed_tweets.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a50128e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading the BERT model and tokenizer\n",
    "model_name = 'bert-base-uncased'\n",
    "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "model = BertModel.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8215d566",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BERT embedding for text\n",
    "def get_bert_embeddings(text):\n",
    "    tokens_text = tokenizer(text, padding=True, truncation=True, return_tensors='pt', max_length=128)\n",
    "    with torch.no_grad():\n",
    "        output = model(**tokens_text)\n",
    "    embeddings = output.last_hidden_state.mean(dim=1)\n",
    "    return embeddings\n",
    "\n",
    "def get_hashtag_embeddings(hashtags):\n",
    "    if isinstance(hashtags, list):\n",
    "        combined_hashtags = ' '.join(hashtags)\n",
    "    else:\n",
    "        combined_hashtags = str(hashtags)\n",
    "    \n",
    "    tokens_hashtags = tokenizer(combined_hashtags, padding=True, truncation=True, return_tensors='pt', max_length=128)\n",
    "    with torch.no_grad():\n",
    "        output = model(**tokens_hashtags)\n",
    "    embeddings = output.last_hidden_state.mean(dim=1)\n",
    "    return embeddings\n",
    "\n",
    "def extract_hashtags(text):\n",
    "    return re.findall(r'#\\w+', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ca6e4127",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['text_bert_embeddings'] = data['Text'].apply(get_bert_embeddings)\n",
    "data['hashtags_bert_embeddings'] = data['Hashtags'].apply(get_hashtag_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "91f5b6ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Post</th>\n",
       "      <th>Text</th>\n",
       "      <th>Hashtags</th>\n",
       "      <th>Clean_Text</th>\n",
       "      <th>Cleaned_Hashtags</th>\n",
       "      <th>text_tokens</th>\n",
       "      <th>hashtags_tokens</th>\n",
       "      <th>input_tokens</th>\n",
       "      <th>numTags</th>\n",
       "      <th>text_bert_embeddings</th>\n",
       "      <th>hashtags_bert_embeddings</th>\n",
       "      <th>hashtag_relevancy_scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Looking Ahead: 17 #Predicted #Marketing #Trend...</td>\n",
       "      <td>Looking Ahead: 17 Predicted Marketing Trends I...</td>\n",
       "      <td>#Predicted #Marketing #Trends #Mobile #AR #VR ...</td>\n",
       "      <td>looking ahead 17 predicted marketing trends in...</td>\n",
       "      <td>['Predicted', 'Marketing', 'Trends', 'Mobile',...</td>\n",
       "      <td>[101, 2559, 3805, 1024, 2459, 10173, 5821, 128...</td>\n",
       "      <td>[[1001], [1052], [1054], [1041], [1040], [1045...</td>\n",
       "      <td>[101, 2559, 3805, 1024, 2459, 10173, 5821, 128...</td>\n",
       "      <td>9</td>\n",
       "      <td>[[tensor(0.1858), tensor(-0.0076), tensor(0.45...</td>\n",
       "      <td>[[tensor(-0.0812), tensor(0.1149), tensor(0.46...</td>\n",
       "      <td>0.709190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RT @simonnash2017: These are the #Top20 #BigDa...</td>\n",
       "      <td>These are the Top20 BigData &amp;amp; AI on twitte...</td>\n",
       "      <td>#Top20 #BigData #AI #twitter #2017 #ITjobs #Da...</td>\n",
       "      <td>these are the top20 bigdata amp ai on twitter ...</td>\n",
       "      <td>['Top20', 'BigData', 'AI', 'twitter', '2017', ...</td>\n",
       "      <td>[101, 2122, 2024, 1996, 2327, 11387, 2502, 285...</td>\n",
       "      <td>[[1001], [1056], [1051], [1052], [1016], [1014...</td>\n",
       "      <td>[101, 2122, 2024, 1996, 2327, 11387, 2502, 285...</td>\n",
       "      <td>10</td>\n",
       "      <td>[[tensor(0.1847), tensor(-0.2179), tensor(0.68...</td>\n",
       "      <td>[[tensor(0.0946), tensor(-0.0150), tensor(0.42...</td>\n",
       "      <td>0.802984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>These are the #Top20 #BigData &amp;amp; #AI on #tw...</td>\n",
       "      <td>These are the Top20 BigData &amp;amp; AI on twitte...</td>\n",
       "      <td>#Top20 #BigData #AI #twitter #2017 #ITjobs #Da...</td>\n",
       "      <td>these are the top20 bigdata amp ai on twitterÂ ...</td>\n",
       "      <td>['Top20', 'BigData', 'AI', 'twitter', '2017', ...</td>\n",
       "      <td>[101, 2122, 2024, 1996, 2327, 11387, 2502, 285...</td>\n",
       "      <td>[[1001], [1056], [1051], [1052], [1016], [1014...</td>\n",
       "      <td>[101, 2122, 2024, 1996, 2327, 11387, 2502, 285...</td>\n",
       "      <td>9</td>\n",
       "      <td>[[tensor(0.1032), tensor(-0.2423), tensor(0.67...</td>\n",
       "      <td>[[tensor(0.0765), tensor(-0.0382), tensor(0.43...</td>\n",
       "      <td>0.799164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RT @Azure: Data is evolving. Find out how to t...</td>\n",
       "      <td>Data is evolving. Find out how to transform yo...</td>\n",
       "      <td>#SQL #Data</td>\n",
       "      <td>data is evolving find out how to transform you...</td>\n",
       "      <td>['SQL', 'Data']</td>\n",
       "      <td>[101, 2951, 2003, 20607, 1012, 2424, 2041, 212...</td>\n",
       "      <td>[[1001], [1055], [1053], [1048], [], [1001], [...</td>\n",
       "      <td>[101, 2951, 2003, 20607, 1012, 2424, 2041, 212...</td>\n",
       "      <td>2</td>\n",
       "      <td>[[tensor(-0.1249), tensor(-0.2571), tensor(0.3...</td>\n",
       "      <td>[[tensor(0.0260), tensor(0.0383), tensor(0.253...</td>\n",
       "      <td>0.668773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>These are the #Top20 #BigData &amp;amp; #AI on #tw...</td>\n",
       "      <td>These are the Top20 BigData &amp;amp; AI on twitte...</td>\n",
       "      <td>#Top20 #BigData #AI #twitter #2017 #ITjobs #Da...</td>\n",
       "      <td>these are the top20 bigdata amp ai on twitter ...</td>\n",
       "      <td>['Top20', 'BigData', 'AI', 'twitter', '2017', ...</td>\n",
       "      <td>[101, 2122, 2024, 1996, 2327, 11387, 2502, 285...</td>\n",
       "      <td>[[1001], [1056], [1051], [1052], [1016], [1014...</td>\n",
       "      <td>[101, 2122, 2024, 1996, 2327, 11387, 2502, 285...</td>\n",
       "      <td>9</td>\n",
       "      <td>[[tensor(0.1032), tensor(-0.2423), tensor(0.67...</td>\n",
       "      <td>[[tensor(0.0765), tensor(-0.0382), tensor(0.43...</td>\n",
       "      <td>0.799164</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Post  \\\n",
       "0  Looking Ahead: 17 #Predicted #Marketing #Trend...   \n",
       "1  RT @simonnash2017: These are the #Top20 #BigDa...   \n",
       "2  These are the #Top20 #BigData &amp; #AI on #tw...   \n",
       "3  RT @Azure: Data is evolving. Find out how to t...   \n",
       "4  These are the #Top20 #BigData &amp; #AI on #tw...   \n",
       "\n",
       "                                                Text  \\\n",
       "0  Looking Ahead: 17 Predicted Marketing Trends I...   \n",
       "1  These are the Top20 BigData &amp; AI on twitte...   \n",
       "2  These are the Top20 BigData &amp; AI on twitte...   \n",
       "3  Data is evolving. Find out how to transform yo...   \n",
       "4  These are the Top20 BigData &amp; AI on twitte...   \n",
       "\n",
       "                                            Hashtags  \\\n",
       "0  #Predicted #Marketing #Trends #Mobile #AR #VR ...   \n",
       "1  #Top20 #BigData #AI #twitter #2017 #ITjobs #Da...   \n",
       "2  #Top20 #BigData #AI #twitter #2017 #ITjobs #Da...   \n",
       "3                                         #SQL #Data   \n",
       "4  #Top20 #BigData #AI #twitter #2017 #ITjobs #Da...   \n",
       "\n",
       "                                          Clean_Text  \\\n",
       "0  looking ahead 17 predicted marketing trends in...   \n",
       "1  these are the top20 bigdata amp ai on twitter ...   \n",
       "2  these are the top20 bigdata amp ai on twitterÂ ...   \n",
       "3  data is evolving find out how to transform you...   \n",
       "4  these are the top20 bigdata amp ai on twitter ...   \n",
       "\n",
       "                                    Cleaned_Hashtags  \\\n",
       "0  ['Predicted', 'Marketing', 'Trends', 'Mobile',...   \n",
       "1  ['Top20', 'BigData', 'AI', 'twitter', '2017', ...   \n",
       "2  ['Top20', 'BigData', 'AI', 'twitter', '2017', ...   \n",
       "3                                    ['SQL', 'Data']   \n",
       "4  ['Top20', 'BigData', 'AI', 'twitter', '2017', ...   \n",
       "\n",
       "                                         text_tokens  \\\n",
       "0  [101, 2559, 3805, 1024, 2459, 10173, 5821, 128...   \n",
       "1  [101, 2122, 2024, 1996, 2327, 11387, 2502, 285...   \n",
       "2  [101, 2122, 2024, 1996, 2327, 11387, 2502, 285...   \n",
       "3  [101, 2951, 2003, 20607, 1012, 2424, 2041, 212...   \n",
       "4  [101, 2122, 2024, 1996, 2327, 11387, 2502, 285...   \n",
       "\n",
       "                                     hashtags_tokens  \\\n",
       "0  [[1001], [1052], [1054], [1041], [1040], [1045...   \n",
       "1  [[1001], [1056], [1051], [1052], [1016], [1014...   \n",
       "2  [[1001], [1056], [1051], [1052], [1016], [1014...   \n",
       "3  [[1001], [1055], [1053], [1048], [], [1001], [...   \n",
       "4  [[1001], [1056], [1051], [1052], [1016], [1014...   \n",
       "\n",
       "                                        input_tokens  numTags  \\\n",
       "0  [101, 2559, 3805, 1024, 2459, 10173, 5821, 128...        9   \n",
       "1  [101, 2122, 2024, 1996, 2327, 11387, 2502, 285...       10   \n",
       "2  [101, 2122, 2024, 1996, 2327, 11387, 2502, 285...        9   \n",
       "3  [101, 2951, 2003, 20607, 1012, 2424, 2041, 212...        2   \n",
       "4  [101, 2122, 2024, 1996, 2327, 11387, 2502, 285...        9   \n",
       "\n",
       "                                text_bert_embeddings  \\\n",
       "0  [[tensor(0.1858), tensor(-0.0076), tensor(0.45...   \n",
       "1  [[tensor(0.1847), tensor(-0.2179), tensor(0.68...   \n",
       "2  [[tensor(0.1032), tensor(-0.2423), tensor(0.67...   \n",
       "3  [[tensor(-0.1249), tensor(-0.2571), tensor(0.3...   \n",
       "4  [[tensor(0.1032), tensor(-0.2423), tensor(0.67...   \n",
       "\n",
       "                            hashtags_bert_embeddings  hashtag_relevancy_scores  \n",
       "0  [[tensor(-0.0812), tensor(0.1149), tensor(0.46...                  0.709190  \n",
       "1  [[tensor(0.0946), tensor(-0.0150), tensor(0.42...                  0.802984  \n",
       "2  [[tensor(0.0765), tensor(-0.0382), tensor(0.43...                  0.799164  \n",
       "3  [[tensor(0.0260), tensor(0.0383), tensor(0.253...                  0.668773  \n",
       "4  [[tensor(0.0765), tensor(-0.0382), tensor(0.43...                  0.799164  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Function to calculate cosine similarity between two vectors\n",
    "def cosine_similarity_vectors(a, b):\n",
    "    cos_sim = cosine_similarity([a], [b])\n",
    "    return cos_sim[0][0]\n",
    "\n",
    "# Function to calculate relevancy score between a hashtag and text\n",
    "def calculate_hashtag_relevancy(hashtag_embeddings, text_embeddings):\n",
    "    # Reshape to 1D\n",
    "    hashtag_embeddings = hashtag_embeddings.reshape(-1)\n",
    "    text_embeddings = text_embeddings.reshape(-1)\n",
    "\n",
    "    relevancy_scores = cosine_similarity_vectors(hashtag_embeddings, text_embeddings)\n",
    "    return relevancy_scores\n",
    "\n",
    "\n",
    "# Convert tensors to numpy arrays\n",
    "data['hashtag_relevancy_scores'] = data.apply(lambda row: calculate_hashtag_relevancy(row['hashtags_bert_embeddings'].numpy(), row['text_bert_embeddings'].numpy()), axis=1)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4e717dd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_columns = ['Post','Text','Hashtags','Clean_Text','Cleaned_Hashtags','text_bert_embeddings','hashtags_bert_embeddings','hashtag_relevancy_scores']\n",
    "filtered_data = data[selected_columns]\n",
    "filtered_data.to_excel('Posts_Hashtags.xlsx', index= False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d95a0350",
   "metadata": {},
   "source": [
    "## Relevancy Score for an Input Twitter Post"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ec250b44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter Twitter Post: \n",
      "Looking Ahead: 17 #Predicted #Marketing #Trends In 2017 - See more at: https://t.co/bnho4Dfuvd #Mobile #AR #VR #Advertising #Data #Chatbots\n"
     ]
    }
   ],
   "source": [
    "# input twitter post\n",
    "twitter_post = input(\"Enter Twitter Post: \\n\")\n",
    "hashtags = extract_hashtags(twitter_post)\n",
    "\n",
    "# BERT embedding for text\n",
    "bert = get_bert_embeddings(twitter_post)\n",
    "hashtag = get_hashtag_embeddings(hashtags)\n",
    "\n",
    "# relevancy score\n",
    "relevancy_score = calculate_hashtag_relevancy(hashtag.numpy(), bert.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1377dd88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- HASHTAG RELEVANCY SCORE ----------\n",
      "Twitter Post: Looking Ahead: 17 #Predicted #Marketing #Trends In 2017 - See more at: https://t.co/bnho4Dfuvd #Mobile #AR #VR #Advertising #Data #Chatbots\n",
      "Score: 0.8420144319534302\n",
      "\n",
      "Relevant Hashtags\n"
     ]
    }
   ],
   "source": [
    "print(f\"---------- HASHTAG RELEVANCY SCORE ----------\\nTwitter Post: {twitter_post}\\nScore: {relevancy_score}\")\n",
    "if relevancy_score<=0.50:\n",
    "    print('\\nNon-Relevant Hashtags')\n",
    "else:\n",
    "    print('\\nRelevant Hashtags')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
